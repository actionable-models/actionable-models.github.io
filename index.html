
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Actionable Models</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>Actionable Models</b>: </br> Unsupervised Offline Reinforcement Learning of Robotic Skills</br> 
                <small>
                    arXiv 2021
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        Yevgen Chebotar
                    </li>
                    <li>
                        Karol Hausman
                    </li>
                    <li>
                        Yao Lu
                    </li>
                    <li>
                        Ted Xiao
                    </li>
                    <li>
                        Dmitry Kalashnikov
                    </li>
                    <li>
                        Jake Varley
                    </li>
                    <br>
                    <li>
                       Alex Irpan
                    </li>
                    <li>
                       Benjamin Eysenbach
                    </li>
                    <li>
                        Ryan Julian
                    </li>
                    <li>
                        Chelsea Finn
                    </li>
                    <li>
                        Sergey Levine
                    </li>
                    <br><br>
                    <a href="https://research.google/teams/brain/robotics/">
                    <image src="img/robotics-at-google.png" height="40px"> Robotics at Google</a> <br><br>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
We consider the problem of learning useful robotic skills from previously collected offline data without access to manually specified rewards or additional online exploration, a setting that is becoming increasingly important for scaling robot learning by reusing past robotic data. In particular, we propose the objective of learning a functional understanding of the environment by learning to reach any goal state in a given dataset. We employ goal-conditioned Q-learning with hindsight relabeling and develop several techniques that enable training in a particularly challenging offline setting. We find that our method can operate on high-dimensional camera images and learn a variety of skills on real robots that generalize to previously unseen scenes and objects. We also show that our method can learn to reach long-horizon goals across multiple episodes, and learn rich representations that can help with downstream tasks through pre-training or auxiliary objectives.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/S3SCR7iYMGA" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>

            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{actionablemodels2021arxiv,
    title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
    author={Yevgen Chebotar and Karol Hausman and Yao Lu and 
            Ted Xiao and Dmitry Kalashnikov and Jake Varley and
            Alex Irpan and Benjamin Eysenbach and Ryan Julian and 
            Chelsea Finn and Sergey Levine},
    journal={arXiv},
    year={2021}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                We would like to thank Benjamin Swanson, Josh Weaver, Noah Brown, Khem Holden, Linda  Luu  and  Brandon  Kinman for  their robot  operation  support, Tom Small for help with videos and project media, Julian  Ibarz, Kanishka  Rao, and  Vincent  Vanhoucke for their managerial support, and all of  the  Robotics  at Google team for their support throughout this project.
                <br><br>
                </p>
            </div>
        </div>
    </div>
</body>
</html>
